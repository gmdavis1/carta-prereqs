{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tJvLhn_UJPs"
   },
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIFgvkvmZtrG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Abood/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import operator\n",
    "from math import log\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "import pyreadr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_U4w3WATCEV"
   },
   "source": [
    "Using Google Drive to store files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUk4eV7f2P_N"
   },
   "outputs": [],
   "source": [
    "passing_grades = [\"A+\", \"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\",\n",
    "                  \"D-\", \"S\", \"CR\"]\n",
    "passing_pattern = r\"A[+-]*|B[+-]*|C[+-]*|D[+-]*|S|CR\"\n",
    "success_grades = [\"A+\", \"A\", \"A-\", \"B+\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8arNKjjOT6v7"
   },
   "source": [
    "# Exploration with toy dataset \"cs_ug.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ7JtzWjZv-p"
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('../data/last_five_years.csv', header=0)\n",
    "# result = pyreadr.read_r('../data/merged_data.rds')\n",
    "# raw_data = result[None]\n",
    "raw_data = pd.read_feather('../data/merged_data.fthr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4879,
     "status": "ok",
     "timestamp": 1576112518244,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "z4TKQN7_Z9Ev",
    "outputId": "3f62a8f7-ad73-46cf-9536-15fabd65e23a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acad_career</th>\n",
       "      <th>strm</th>\n",
       "      <th>class_nbr</th>\n",
       "      <th>stdnt_enrl_status</th>\n",
       "      <th>unt_taken</th>\n",
       "      <th>unt_prgrss</th>\n",
       "      <th>grading_basis_dt</th>\n",
       "      <th>unt_billing</th>\n",
       "      <th>grading_scheme_enr</th>\n",
       "      <th>crse_grade_off</th>\n",
       "      <th>...</th>\n",
       "      <th>crse_id</th>\n",
       "      <th>effdt</th>\n",
       "      <th>major1</th>\n",
       "      <th>major2</th>\n",
       "      <th>major3</th>\n",
       "      <th>major4</th>\n",
       "      <th>major5</th>\n",
       "      <th>major6</th>\n",
       "      <th>major7</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UG</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>21562.0</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>REG</td>\n",
       "      <td>A+</td>\n",
       "      <td>...</td>\n",
       "      <td>202740.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acad_career    strm  class_nbr stdnt_enrl_status  unt_taken  unt_prgrss  \\\n",
       "10          UG  1184.0    21562.0                 E        2.0         2.0   \n",
       "\n",
       "   grading_basis_dt  unt_billing grading_scheme_enr crse_grade_off  ...  \\\n",
       "10       2018-01-10          2.0                REG             A+  ...   \n",
       "\n",
       "     crse_id effdt major1 major2 major3 major4 major5 major6 major7 sex  \n",
       "10  202740.0  None   None   None   None   None   None   None   None   M  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.loc[[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acad_career', 'strm', 'class_nbr', 'stdnt_enrl_status', 'unt_taken',\n",
       "       'unt_prgrss', 'grading_basis_dt', 'unt_billing', 'grading_scheme_enr',\n",
       "       'crse_grade_off', 'crse_grade_input', 'earn_credit', 'oprid',\n",
       "       'last_upd_dt_stmp', 'last_upd_tm_stmp', 'emplid', 'subject',\n",
       "       'ssr_component', 'catalog_nbr', 'crse_acad_group', 'crse_acad_org',\n",
       "       'crse_id', 'effdt', 'major1', 'major2', 'major3', 'major4', 'major5',\n",
       "       'major6', 'major7', 'sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winter is 4, Spring is 6, Fall is 2, Summer is 8?\n",
    "e.g. 1198 is 18-19, summer quarter. 1196 is 18-19, spring quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djV-nd26Z_tL"
   },
   "outputs": [],
   "source": [
    "#all allowed quarters\n",
    "terms = raw_data.strm.unique()\n",
    "terms = list(filter(lambda x: x >= 1162, terms)) \n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_name (row):\n",
    "    if row['subject'] != None and row['catalog_nbr'] != None:\n",
    "        return row['subject']+row['catalog_nbr']\n",
    "    return \"\"\n",
    "def student_gender (row):\n",
    "    if row['sex'] == \"F\":\n",
    "        return 1\n",
    "    return 0\n",
    "def dropped_function (row):\n",
    "    if row['stdnt_enrl_status'] == 'D':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_courses = raw_data.loc[raw_data['acad_career'] == \"UG\"]\n",
    "# new_courses['course_name'] = new_courses.apply(lambda row: course_name(row), axis=1)\n",
    "# new_courses['female'] = new_courses.apply(lambda row: student_gender(row), axis=1)\n",
    "# new_courses['dropped'] = new_courses.apply(lambda row: dropped_function(row), axis=1)\n",
    "# new_courses = new_courses.drop(['ssr_component', 'crse_grade_off', 'last_upd_dt_stmp',\n",
    "#                                 'last_upd_tm_stmp', 'class_nbr', 'stdnt_enrl_status',\n",
    "#                                 'unt_taken', 'unt_prgrss', 'grading_basis_dt', 'unt_billing',\n",
    "#                                 'grading_scheme_enr', 'crse_acad_group', 'crse_acad_org', 'crse_id',\n",
    "#                                 'effdt', 'major1', 'major2', 'major3', 'major4', 'major5', 'major6', 'major7',\n",
    "#                                 'catalog_nbr', 'oprid', 'sex'], axis=1)\n",
    "# new_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_courses_mod = new_courses.drop(['ssr_component', 'crse_acad_group', 'crse_grade_off', 'last_upd_dt_stmp',\n",
    "                                'last_upd_tm_stmp', 'class_nbr',\n",
    "                                'grading_basis_dt', 'effdt', 'unt_prgrss',\n",
    "                                'grading_scheme_enr', 'crse_id',\n",
    "                                'major1', 'major2', 'major3', 'major4', 'major5', 'major6', 'major7', 'oprid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_courses_mod.to_csv('../data/clean_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acad_career</th>\n",
       "      <th>strm</th>\n",
       "      <th>stdnt_enrl_status</th>\n",
       "      <th>unt_taken</th>\n",
       "      <th>unt_billing</th>\n",
       "      <th>crse_grade_input</th>\n",
       "      <th>earn_credit</th>\n",
       "      <th>emplid</th>\n",
       "      <th>subject</th>\n",
       "      <th>catalog_nbr</th>\n",
       "      <th>crse_acad_org</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UG</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>E</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>$2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...</td>\n",
       "      <td>MATH</td>\n",
       "      <td>51</td>\n",
       "      <td>MATH</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UG</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>$2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>31X</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UG</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>E</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>$2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>31X</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UG</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>E</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A-</td>\n",
       "      <td>Y</td>\n",
       "      <td>$2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...</td>\n",
       "      <td>LINGUIST</td>\n",
       "      <td>35</td>\n",
       "      <td>LINGUISTIC</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>$2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...</td>\n",
       "      <td>MATH</td>\n",
       "      <td>51</td>\n",
       "      <td>MATH</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667926</th>\n",
       "      <td>UG</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...</td>\n",
       "      <td>AFRICAST</td>\n",
       "      <td>195</td>\n",
       "      <td>AFRICAST</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667927</th>\n",
       "      <td>UG</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...</td>\n",
       "      <td>UAR</td>\n",
       "      <td>42B</td>\n",
       "      <td>VPUE</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667928</th>\n",
       "      <td>UG</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...</td>\n",
       "      <td>UAR</td>\n",
       "      <td>56</td>\n",
       "      <td>VPUE</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667929</th>\n",
       "      <td>UG</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...</td>\n",
       "      <td>HUMRTS</td>\n",
       "      <td>108</td>\n",
       "      <td>ICA</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667930</th>\n",
       "      <td>UG</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...</td>\n",
       "      <td>SPANLANG</td>\n",
       "      <td>108SL</td>\n",
       "      <td>LANGCTR</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2667931 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acad_career    strm stdnt_enrl_status  unt_taken  unt_billing  \\\n",
       "0                UG  1182.0                 E        5.0          5.0   \n",
       "1                UG  1182.0                 E        0.0          0.0   \n",
       "2                UG  1182.0                 E        5.0          5.0   \n",
       "3                UG  1182.0                 E        4.0          4.0   \n",
       "4                UG  1182.0                 E        0.0          0.0   \n",
       "...             ...     ...               ...        ...          ...   \n",
       "2667926          UG  1204.0                 E        2.0          2.0   \n",
       "2667927          UG  1204.0                 E        1.0          1.0   \n",
       "2667928          UG  1204.0                 E        1.0          1.0   \n",
       "2667929          UG  1204.0                 E        3.0          3.0   \n",
       "2667930          UG  1204.0                 E        3.0          3.0   \n",
       "\n",
       "        crse_grade_input earn_credit  \\\n",
       "0                      A           Y   \n",
       "1                   None           N   \n",
       "2                      A           Y   \n",
       "3                     A-           Y   \n",
       "4                   None           N   \n",
       "...                  ...         ...   \n",
       "2667926             None           Y   \n",
       "2667927             None           Y   \n",
       "2667928             None           Y   \n",
       "2667929             None           Y   \n",
       "2667930             None           Y   \n",
       "\n",
       "                                                    emplid   subject  \\\n",
       "0        $2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...      MATH   \n",
       "1        $2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...      CHEM   \n",
       "2        $2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...      CHEM   \n",
       "3        $2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...  LINGUIST   \n",
       "4        $2a$15$.iQPCHeeuyLD3TIqJRk4j.LU0IjGYumSdFkAEUf...      MATH   \n",
       "...                                                    ...       ...   \n",
       "2667926  ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...  AFRICAST   \n",
       "2667927  ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...       UAR   \n",
       "2667928  ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...       UAR   \n",
       "2667929  ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...    HUMRTS   \n",
       "2667930  ZZY9cXv8E+kma1UpxorU3h6lmrEAShLb3z/uaqmJdU+YHG...  SPANLANG   \n",
       "\n",
       "        catalog_nbr crse_acad_org sex  \n",
       "0                51          MATH   M  \n",
       "1               31X     CHEMISTRY   M  \n",
       "2               31X     CHEMISTRY   M  \n",
       "3                35    LINGUISTIC   M  \n",
       "4                51          MATH   M  \n",
       "...             ...           ...  ..  \n",
       "2667926         195      AFRICAST   F  \n",
       "2667927         42B          VPUE   F  \n",
       "2667928          56          VPUE   F  \n",
       "2667929         108           ICA   F  \n",
       "2667930       108SL       LANGCTR   F  \n",
       "\n",
       "[2667931 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_courses_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICeMH9VWaE0L"
   },
   "outputs": [],
   "source": [
    "# new_courses is the entries post 2010\n",
    "new_courses = raw_data.loc[raw_data['strm'].isin(terms)]\n",
    "unique_course_list = new_courses.course_name.unique()\n",
    "num_students = len(new_courses.emplid.unique())\n",
    "num_courses = len(unique_course_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SB7Z0hQpaNyl"
   },
   "outputs": [],
   "source": [
    "def getStudentFeatures(course):\n",
    "    course_entries = cs_ugrad.loc[cs_ugrad['course_name'] == course] # all course entries that are about the certain course we want\n",
    "    print(course_entries['crse_grade_input'].unique())\n",
    "    letter_entries = course_entries[(course_entries['crse_grade_input'] == 'A+') | (course_entries['crse_grade_input'] == 'A') | (course_entries['crse_grade_input'] == 'A-') | \n",
    "                                 (course_entries['crse_grade_input'] == 'B+') | (course_entries['crse_grade_input'] == 'B') | (course_entries['crse_grade_input'] == 'B-') |\n",
    "                                 (course_entries['crse_grade_input'] == 'C+') | (course_entries['crse_grade_input'] == 'C') | (course_entries['crse_grade_input'] == 'C-') |\n",
    "                                 (course_entries['crse_grade_input'] == 'D+') | (course_entries['crse_grade_input'] == 'D') | (course_entries['crse_grade_input'] == 'D-') |\n",
    "                                 (course_entries['crse_grade_input'] == 'NP') | (course_entries['crse_grade_input'] == 'W')]\n",
    "    a = np.zeros(shape=(len(letter_entries),num_courses)) # all 0 initialized features matrix\n",
    "    X = pd.DataFrame(a,columns=unique_course_list) # same as above, but in pandas to allow indexing by course name\n",
    "    y = np.zeros(shape=(len(letter_entries),1)) # outcome vector\n",
    "    for counter, idx in enumerate(letter_entries.index): # loop over all class entried\n",
    "    # fill outcome vector y\n",
    "      grade = letter_entries.loc[[idx]]['crse_grade_input']\n",
    "      # print(grade.unique())\n",
    "      gradeStr = grade.tolist()[0]\n",
    "      if (gradeStr == \"A+\" or gradeStr == \"A\" or\n",
    "          gradeStr == \"A-\" or gradeStr == \"B+\"):\n",
    "        y[counter] = 1\n",
    "        # fill predictor matrix X\n",
    "        std_id = letter_entries.loc[[idx]]['emplid'] # Get the student id\n",
    "        quarter = letter_entries.loc[[idx]]['strm'] # Get the term\n",
    "        student_courses = cs_ugrad.loc[cs_ugrad['emplid'] == std_id.tolist()[0]] # Get all courses the student took\n",
    "        student_courses = student_courses.loc[student_courses['strm'] < quarter.tolist()[0]] # Filter the courses to be only before the course of interest\n",
    "        student_courses = student_courses.loc[student_courses['strm'] >= 1100] # Filter the courses to only be after 2010\n",
    "        for j in student_courses.index:# Loop over the student's courses\n",
    "            course_name = student_courses.loc[[j]]['course_name'] # Get the course name\n",
    "            grade = student_courses.loc[[j]]['crse_grade_input']\n",
    "            gradeStr = grade.tolist()[0]\n",
    "            if (gradeStr == \"A+\" or gradeStr == \"A\" or\n",
    "                gradeStr == \"A-\" or gradeStr == \"B+\" or gradeStr == \"B\" or\n",
    "                gradeStr == \"B-\" or gradeStr == \"C+\" or gradeStr == \"C\" or\n",
    "                gradeStr == \"C-\" or gradeStr == \"D+\" or gradeStr == \"D\" or\n",
    "                gradeStr == \"D-\"):\n",
    "              X.iloc[counter, X.columns.get_loc(course_name.tolist()[0])] = 1 # Set the course name in X to the new value (or if it was already passed keep the value)\n",
    "            dev_break = True\n",
    "    return X,y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCBygHJf7p8F"
   },
   "outputs": [],
   "source": [
    "X_110 = pd.read_pickle(DATA_PATH+\"/CS110_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS110_y.npy\")\n",
    "X_229 = pd.read_pickle(DATA_PATH+\"/CS229_X.pkl\")\n",
    "y_229 = np.load(DATA_PATH+\"/CS229_y.npy\")\n",
    "X_230 = pd.read_pickle(DATA_PATH+\"/CS230_X.pkl\")\n",
    "y_230 = np.load(DATA_PATH+\"/CS230_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 68405,
     "status": "ok",
     "timestamp": 1576112647737,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "KanvlFdnaPyO",
    "outputId": "610390b1-3f4d-4bcd-89cf-3a003687c207"
   },
   "outputs": [],
   "source": [
    "X_110,y_110 = getStudentFeatures('CS110')\n",
    "X_229,y_229 = getStudentFeatures('CS229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10589,
     "status": "ok",
     "timestamp": 1576112723226,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "aNqhw-U3ozkD",
    "outputId": "85507fce-5851-4674-bf85-a3d80a1a56ec"
   },
   "outputs": [],
   "source": [
    "X_230,y_230 = getStudentFeatures('CS230')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1576126190569,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "kGJy20SvcMz8",
    "outputId": "c2c18848-bfbb-429f-db92-7babd4574a97"
   },
   "outputs": [],
   "source": [
    "collections.Counter(y_229)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqiIgoCnfSon"
   },
   "source": [
    "# Try sklearn logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jNaMvCWfYHJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-B210Y7qpOm"
   },
   "outputs": [],
   "source": [
    "# Use the X predictor matrix and y outcome vector from \n",
    "# getStudentFeatures, fit a logistic regression model and return\n",
    "# the list of coefficients, default sorted by absolute value\n",
    "\n",
    "# Params: sort = [\"pos\", \"neg\", \"abs\"] to sort by largest positive, negative, or\n",
    "# absolute value of coefficients\n",
    "def get_coefs(X, y, sort = \"abs\"):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  model = LogisticRegression(solver=\"lbfgs\")\n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_test,y_test) \n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  coefs = [(X.columns[i], model.coef_[0][i]) for i in range(len(X.columns))]\n",
    "  if sort:\n",
    "    if sort == \"pos\":\n",
    "      coefs = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "    if sort == \"neg\":\n",
    "      coefs = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "    if sort == \"abs\":\n",
    "      coefs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "  return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1576112742357,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "liTHwjSlfmjR",
    "outputId": "6b8b7bc6-5a46-4005-c0fd-c726cdb65093"
   },
   "outputs": [],
   "source": [
    "CS110coefs = get_coefs(X_110, y_110)\n",
    "CS110coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1576112748080,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "TNZZvCiPJSfb",
    "outputId": "61dc2b86-8a95-4349-9d01-b12368de7392"
   },
   "outputs": [],
   "source": [
    "CS230coefs = get_coefs(X_230, y_230)\n",
    "CS230coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1576112829480,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "RinYEpeB6Nn-",
    "outputId": "db156b37-b00e-452e-aae2-b896e56d8d3a"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "CS229coefs = get_coefs(X_229, y_229)\n",
    "CS229coefs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5QQgnfLcWZj"
   },
   "source": [
    "More Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKapRneTygGa"
   },
   "outputs": [],
   "source": [
    "CS110coefs = get_coefs(X_high, y, 'pos')\n",
    "CS110coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-grrM2pSr6dn"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS106B\")\n",
    "CS106Bcoefs = get_coefs(X, y)\n",
    "CS106Bcoefs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1m1vLHAs-cX"
   },
   "source": [
    "GLENN: It seems like at least for CS110 and CS106B, the largest predictor is having taken that course beforehand, and it's a negative coefficient. Seems strange. Let's look into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-50OF5Hudv3"
   },
   "outputs": [],
   "source": [
    "course_entries = cs_ugrad.loc[cs_ugrad['course_name'] == \"CS110\"]\n",
    "counts = course_entries['emplid'].value_counts()\n",
    "mult_emplids = counts[counts > 1].index\n",
    "mult_students = course_entries.loc[course_entries['emplid'].isin(mult_emplids)]\n",
    "mult_students.sort_values(['emplid','strm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkARsLLty_7H"
   },
   "outputs": [],
   "source": [
    "# GLENN:\n",
    "# Not sure what's going on with emplid 22166: [NC, drop, W, drop]\n",
    "# shouldn't be showing up as containing a passing grade but the\n",
    "# other results look right\n",
    "\n",
    "for emplid in mult_emplids:\n",
    "  one_student = course_entries.loc[course_entries['emplid'] == emplid].sort_values(['strm'])\n",
    "  if one_student['crse_grade_input'].str.contains(passing_pattern, na = False).any():\n",
    "    print(one_student[['strm', 'crse_grade_input', 'dropped', 'emplid']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hA4N7g1W0sbe"
   },
   "source": [
    "GLENN: Looks like this may be due to a small number of students taking and passing the course with a low grade, and then considering taking it again for a better grade but dropping it instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LXz1_Tk7f_l"
   },
   "source": [
    "GLENN: Let's look at positive coefficients for now. I picked a few courses as samples below: the prereqs kind of make sense but we definitely need to find some ways to refine this further. Maybe doing something with the number of students who took a certain prereq? If only a small number of students took a prereq that could lead to huge coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucae9td17TKg"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS110\")\n",
    "CS110coefs = get_coefs(X, y, \"pos\")\n",
    "CS110coefs[:20]\n",
    "\n",
    "# contains CS107 and CS107E in top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZL3mFte8_te"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS229\")\n",
    "CS229coefs = get_coefs(X, y, \"pos\")\n",
    "CS229coefs[:20]\n",
    "\n",
    "# nothing stands out to me here; maybe it's because CS229 is more\n",
    "# of a math course so the strong predictors might be MATH51 or\n",
    "# other non-CS courses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFyDbGtV93RX"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS221\")\n",
    "CS221coefs = get_coefs(X, y, \"pos\")\n",
    "CS221coefs[:20]\n",
    "\n",
    "# contains CS224S, which is a \"postreq\" (221 is prereq for 224S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KD1VZRAAK3Hi"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS547\")\n",
    "CS224Scoefs = get_coefs(X, y, \"pos\")\n",
    "CS224Scoefs[:20]\n",
    "\n",
    "# contains CS224S, which is a \"postreq\" (221 is prereq for 224S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRstpRwD94_l"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS224N\")\n",
    "CS224Ncoefs = get_coefs(X, y, \"pos\")\n",
    "CS224Ncoefs[:20]\n",
    "\n",
    "# contains CS221, 229, 229A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRfFR05D-iPa"
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle(DATA_PATH+\"/CS224N_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS224N_y.npy\")\n",
    "CS224Ncoefs = get_coefs(X, y, \"pos\")\n",
    "CS224Ncoefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ_1gAvI95KA"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS230\")\n",
    "CS230coefs = get_coefs(X, y, \"pos\")\n",
    "CS230coefs[:20]\n",
    "\n",
    "# doesn't contain CS229, which I would have expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPTv49xN7mDd"
   },
   "source": [
    "GLENN: How should we interpret negative coefficients? The model suggests that passing these other courses beforehand predicts that you won't pass the course in question, but that seems weird. There isn't an obvious reason why passing CS224U should make you less prepared for CS110, for example.\n",
    "\n",
    "YITIAN: I thought negative weights should just be interpreted as less likely to be helpful in passing certain class. Although implemented a bit differently in scikit, it still follows the general sigmoid function where the negative weights would make the sigmoid really small (since all the inputs X is positive) therefore less likely to be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tgg2VEj7sHi"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS110\")\n",
    "CS110coefs = get_coefs(X, y, \"neg\")\n",
    "CS110coefs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IPh751NOqBY"
   },
   "source": [
    "Things to try:\n",
    "- PCA\n",
    "- Collaborative filtering to detect feature vectors of classes, then cluster them? (Is this just more complicated PCA?)\n",
    "- Adjust $\\lambda$ for normalization\n",
    "- Change it so the coefficients are all $e^{\\text{coef}}$ (all positive), requires some kind of transformation to log space?\n",
    "- Full dataset instead of just CS, find predictors in other departments\n",
    "- Weighted regression or some kind of significance indicator to account for the predictors with very few data points\n",
    "\n",
    "Interpretations:\n",
    "- What do we do with negative coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8I-xhJBawaD"
   },
   "source": [
    "# **Compare different Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJWycp_p6htr"
   },
   "outputs": [],
   "source": [
    "def runDifferentModels(X,y):\n",
    "  # split X and y into training and testing sets\n",
    "  X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3)\n",
    "  X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "  print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  #\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\"Naive Bayes\", \"QDA\"\n",
    "  models = []\n",
    "  models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "  models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "  models.append(('GP', GaussianProcessClassifier()))\n",
    "  models.append(('RF', RandomForestClassifier()))\n",
    "  models.append(('NN', MLPClassifier()))\n",
    "  models.append(('AB', AdaBoostClassifier()))\n",
    "  models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "  models.append(('CART', DecisionTreeClassifier()))\n",
    "  models.append(('NB', GaussianNB()))\n",
    "  models.append(('K_M', KNeighborsClassifier(metric = 'minkowski')))\n",
    "  models.append(('K_C', KNeighborsClassifier(metric = 'chebyshev')))\n",
    "  models.append(('K_E', KNeighborsClassifier(metric = 'euclidean')))\n",
    "  models.append(('K_Man', KNeighborsClassifier(metric = 'manhattan')))\n",
    "  models.append(('K_Mat', KNeighborsClassifier(metric = 'matching')))\n",
    "  models.append(('K_J', KNeighborsClassifier(metric = 'jaccard')))\n",
    "  models.append(('K_D', KNeighborsClassifier(metric = 'dice')))\n",
    "  models.append(('K_K', KNeighborsClassifier(metric = 'kulsinski')))\n",
    "  models.append(('S_Lin', SVC(kernel='linear')))\n",
    "  models.append(('S_RBF', SVC(kernel='rbf')))\n",
    "  models.append(('S_Sig', SVC(kernel=\"sigmoid\")))\n",
    "  models.append(('S_Pol', SVC(kernel=\"poly\")))\n",
    "  \n",
    "\n",
    "  # Evaluate each model through 10-fold cross-validation\n",
    "  results = []\n",
    "  names = []\n",
    "  number = 1\n",
    "  for name, model in models:\n",
    "      kfold = KFold(n_splits=10, random_state=42)\n",
    "      cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "      results.append(cv_results)\n",
    "      names.append(name)\n",
    "      msg = \"%i) %s: Mean = %f with std = (%f)\" % (number, name, cv_results.mean(), cv_results.std())\n",
    "      number += 1\n",
    "      print(msg)\n",
    "  # Compare Algorithms\n",
    "  matplotlib.rcParams.update({'font.size': 40})\n",
    "  fig = plt.figure()\n",
    "  fig = plt.figure(figsize=(28,20))\n",
    "  plt.title('Algorithm Comparison')\n",
    "  ax = fig\n",
    "  medianprops = {'color': 'magenta', 'linewidth': 6}\n",
    "  boxprops = {'color': 'black', 'linewidth': 4, 'linestyle': '-'}\n",
    "  whiskerprops = {'color': 'black', 'linewidth': 4, 'linestyle': '-'}\n",
    "  capprops = {'color': 'black', 'linewidth': 4, 'linestyle': '-'}\n",
    "  flierprops = {'color': 'black', 'marker': 'x'}\n",
    "  plt.boxplot(results,\n",
    "           medianprops=medianprops,\n",
    "           boxprops=boxprops,\n",
    "           whiskerprops=whiskerprops,\n",
    "           capprops=capprops,\n",
    "           flierprops=flierprops)\n",
    "#   ax.set_xticklabels(names)\n",
    "  plt.xlabel('Model Number', fontsize=40)\n",
    "  plt.ylabel('Accuracy', fontsize=40)\n",
    "  plt.savefig(DATA_PATH+'/visualizations/comparison_110_B+.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdHzxdELEJug"
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X_110)\n",
    "\n",
    "# X_train (10 input features, 70% of full dataset), X_val (10 input features, 15% of full dataset), X_test (10 input features, 15% of full dataset)\n",
    "# Y_train (1 label, 70% of full dataset), Y_val (1 label, 15% of full dataset), Y_test (1 label, 15% of full dataset)\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y_110, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 385551,
     "status": "ok",
     "timestamp": 1576114118190,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "0slCkshACaoh",
    "outputId": "b08dfdcb-4393-4c9b-8ddc-c2dea4d43198"
   },
   "outputs": [],
   "source": [
    "runDifferentModels(X_110,y_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-duNVM_F7sY"
   },
   "outputs": [],
   "source": [
    "plt.savefig(DATA_PATH+'/visualizations/comparison_229.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ESo0pl1cO8W"
   },
   "source": [
    "# **NeurralNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74768,
     "status": "ok",
     "timestamp": 1576114375360,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "6IVXebsvVBRV",
    "outputId": "f51fc6c8-d9e0-4080-bee5-17482cf2780a"
   },
   "outputs": [],
   "source": [
    "def runNeuralNet(X,y):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "    # X_train (10 input features, 70% of full dataset), X_val (10 input features, 15% of full dataset), X_test (10 input features, 15% of full dataset)\n",
    "    # Y_train (1 label, 70% of full dataset), Y_val (1 label, 15% of full dataset), Y_test (1 label, 15% of full dataset)\n",
    "    X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "    # values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "    # for param in values:\n",
    "    #     # model = Sequential([Dense(32, activation='relu', input_shape=(58,)), Dense(32, activation='relu'), Dense(1, activation='sigmoid'),]) # described sequentially, layer-by-layer with 32, 32, and 1 neurons; 58 input features\n",
    "    #     print(\"Param = \" + str(param))\n",
    "        \n",
    "    # SGD Optimizer\n",
    "    param = 1e-3\n",
    "    model = Sequential([Dense(100, activation='relu', input_shape=(1022,), kernel_regularizer=l1(param)), Dense(100, activation='relu', kernel_regularizer=l1(param)), Dense(100, activation='relu', kernel_regularizer=l1(param)), Dense(1, activation='sigmoid'),]) # described sequentially, layer-by-layer with 32, 32, and 1 neurons; 58 input features\n",
    "    # model = Sequential([Dense(32, activation='relu', input_shape=(58,), kernel_regularizer=l2(param)), Dense(32, activation='relu', kernel_regularizer=l2(param)), Dense(1, activation='sigmoid'),]) # described sequentially, layer-by-layer with 32, 32, and 1 neurons; 58 input features\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "    history = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
    "\n",
    "    # Plot epoch vs. accuracy plot\n",
    "    fig = plt.figure(figsize=(28,20))\n",
    "    plt.plot(history.history['acc'], linewidth=7)\n",
    "    plt.plot(history.history['val_acc'], linewidth=7)\n",
    "    plt.plot(history.history['loss'], linewidth=7)\n",
    "    plt.plot(history.history['val_loss'], linewidth=7)\n",
    "    plt.rcParams.update({'font.size': 40})\n",
    "    plt.title('SGD Model Training Loss and Accuracy')\n",
    "    plt.ylabel('Accuracy/Loss', fontsize=40)\n",
    "    plt.xlabel('Epoch', fontsize=40)\n",
    "    plt.legend(['Acc_Train', 'Acc_Val', 'Loss_Train', 'Loss_Val'], loc='upper right')\n",
    "    plt.savefig(DATA_PATH+'/visualizations/SGD_110_B+.png')\n",
    "    print(\"SGD Accuracy: \" + str(model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "    param = 1e-2\n",
    "    # Adam optimizer\n",
    "    model_2 = Sequential([Dense(100, activation='relu', input_shape=(1022,), kernel_regularizer=l2(param)), Dense(100, activation='relu'), Dense(100, activation='relu'), Dense(1, activation='sigmoid'),])\n",
    "    model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history2 = model_2.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
    "\n",
    "    # Plot epoch vs. accuracy plot\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(28,20))\n",
    "    plt.plot(history2.history['acc'], linewidth=7)\n",
    "    plt.plot(history2.history['val_acc'], linewidth=7)\n",
    "    plt.plot(history2.history['loss'], linewidth=7)\n",
    "    plt.plot(history2.history['val_loss'], linewidth=7)\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    # plt.figure(figsize=(14,10))\n",
    "    plt.title('Adam Model Training Loss and Accuracy')\n",
    "    plt.ylabel('Accuracy/Loss', fontsize=40)\n",
    "    plt.xlabel('Epoch', fontsize=40)\n",
    "    plt.legend(['Acc_Train', 'Acc_Val', 'Loss_Train', 'Loss_Val'], loc='upper right')\n",
    "    plt.savefig(DATA_PATH+'/visualizations/Adam_110_B+.png')\n",
    "    print(\"Adam Accuracy: \" + str(model_2.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "    print(\"Success!\")\n",
    "\n",
    "runNeuralNet(X_110, y_110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2Xs7zWa_eo"
   },
   "source": [
    "# **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4968,
     "status": "ok",
     "timestamp": 1576114784779,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "GgMTebOcxdle",
    "outputId": "70c1b17c-6c88-40ec-b8f7-84e01fba8df9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "principalComponents = pca.fit_transform(X_110)\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "CS110coefs = get_coefs(principalDf, y_110)\n",
    "CS110coefs[:20]\n",
    "pca = PCA().fit(X_110)\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "matplotlib.rcParams.update({'font.size': 40})\n",
    "fig = plt.figure()\n",
    "fig = plt.figure(figsize=(28,20))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), lw=7)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Dataset Explained Variance')\n",
    "plt.savefig(DATA_PATH+\"/visualizations/PCA_110_B+.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbTU_1kiiYJC"
   },
   "source": [
    "# **Baseline Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isgFEoPmj_bp"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "DATA_PATH = \"/content/drive/My Drive/CS129 Carta project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWCO_ajpuSI6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFEUpQ9Kzj0_"
   },
   "outputs": [],
   "source": [
    "# Use the X predictor matrix and y outcome vector from \n",
    "# getStudentFeatures, fit a logistic regression model and return\n",
    "# the list of coefficients, default sorted by absolute value\n",
    "\n",
    "# Params: sort = [\"pos\", \"neg\", \"abs\"] to sort by largest positive, negative, or\n",
    "# absolute value of coefficients\n",
    "\n",
    "# modified get_coefs function to include training and test sets as well as output model scores\n",
    "def get_coefs(X_train, X_test, y_train, y_test, sort = \"abs\"):\n",
    "  model = LogisticRegression(solver=\"lbfgs\", C=1, max_iter=100, multi_class=\"multinomial\") # multinomial enables softmax \n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_train,y_train)\n",
    "  test_score = model.score(X_test,y_test)\n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  print(\"test accuracy: %s\" % test_score)\n",
    "\n",
    "  coefs = [(X_train.columns[i], model.coef_[0][i]) for i in range(len(X_train.columns))]\n",
    "  if sort:\n",
    "    if sort == \"pos\":\n",
    "      coefs = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "    if sort == \"neg\":\n",
    "      coefs = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "    if sort == \"abs\":\n",
    "      coefs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "  return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k4qNRbotNif"
   },
   "outputs": [],
   "source": [
    "#split the data to train and test set\n",
    "X = pd.read_pickle(DATA_PATH+\"/CS142_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS142_y.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "coefs = get_coefs(X_train, X_test, y_train, y_test, \"pos\")\n",
    "coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xX52QrLQ4407"
   },
   "outputs": [],
   "source": [
    "#plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    matplotlib.rcParams.update({'font.size': 40})\n",
    "    fig = plt.figure()\n",
    "    fig = plt.figure(figsize=(28,20))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\", lw=7)\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\", lw=7)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1576114994025,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "EVIEjeopxibc",
    "outputId": "297054ca-c5e0-46a8-f9c1-b51d884cb614"
   },
   "outputs": [],
   "source": [
    "collections.Counter(y_230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12818,
     "status": "ok",
     "timestamp": 1576117173518,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "vX-BDvVk5rYQ",
    "outputId": "406ff193-93b2-4297-c14c-5e40b0d54e92"
   },
   "outputs": [],
   "source": [
    "title = \"Learning Cruves (CS230)\"\n",
    "X = pd.read_pickle(DATA_PATH+\"/CS229_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS229_y.npy\")\n",
    "\n",
    "\n",
    "# Cross validation with 10 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=2, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "plot_learning_curve(estimator, title, X_230, y_230, cv=cv, n_jobs=8)\n",
    "plt.savefig(DATA_PATH+\"/visualizations/learning_curve_230_B+.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9Uxe03bFASX"
   },
   "outputs": [],
   "source": [
    "def plot_validation_curves(title, param_name, param_range, train_scores, test_scores):\n",
    "  train_scores_mean = np.mean(train_scores, axis=1)\n",
    "  train_scores_std = np.std(train_scores, axis=1)\n",
    "  test_scores_mean = np.mean(test_scores, axis=1)\n",
    "  test_scores_std = np.std(test_scores, axis=1)\n",
    "  \n",
    "  matplotlib.rcParams.update({'font.size': 40})\n",
    "  fig = plt.figure()\n",
    "  fig = plt.figure(figsize=(28,20))\n",
    "  plt.title(title)\n",
    "  plt.xlabel(param_name)\n",
    "  plt.ylabel(\"Score\")\n",
    "  lw = 7\n",
    "  \n",
    "  plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "  plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "  plt.legend(loc=\"best\")\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12812,
     "status": "ok",
     "timestamp": 1576115386473,
     "user": {
      "displayName": "Abdallah Anees AbuHashem",
      "photoUrl": "",
      "userId": "08758950724381327734"
     },
     "user_tz": 480
    },
    "id": "yYMV_KisArpp",
    "outputId": "2e112765-40d6-435c-bc6d-beb06cb19b1d"
   },
   "outputs": [],
   "source": [
    "#plot validation curves\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# X = pd.read_pickle(DATA_PATH+\"/CS106B_X_plus.pkl\")\n",
    "# y = np.load(DATA_PATH+\"/CS106B_y_plus.npy\")\n",
    "\n",
    "param_range= [50, 100, 200, 400]\n",
    "estimator = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "train_scores, test_scores = validation_curve(estimator, X_230, y_230, param_name=\"max_iter\", param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=8)\n",
    "\n",
    "title=\"Validation Curve of CS230 with Logistic Regression\"\n",
    "plot_validation_curves(title,\"max_iter\",param_range,train_scores,test_scores)\n",
    "plt.savefig(DATA_PATH+\"/visualizations/validation_curve_230_B+.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Il3igvijKh0p"
   },
   "source": [
    "**CS110**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rZgGKrQKkQw"
   },
   "outputs": [],
   "source": [
    "title = \"Learning Cruves (CS110)\"\n",
    "X = pd.read_pickle(DATA_PATH+\"/CS110_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS110_y.npy\")\n",
    "\n",
    "# Cross validation with 10 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1ekd_3LLmDK"
   },
   "outputs": [],
   "source": [
    "#checking iterations\n",
    "param_range= [50, 100, 200, 400]\n",
    "estimator = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "train_scores, test_scores = validation_curve(estimator, X, y, param_name=\"max_iter\", param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "title=\"Iteration Curve of CS110 with Logistic Regression\"\n",
    "plot_validation_curves(title,\"max_iter\",param_range,train_scores,test_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-DK0pWZMHws"
   },
   "outputs": [],
   "source": [
    "#checking regularizations\n",
    "param_range= [1.0, 2.0, 4.0, 8.0]\n",
    "estimator = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "train_scores, test_scores = validation_curve(estimator, X, y, param_name=\"C\", param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "title=\"Regularization Curve of CS110 with Logistic Regression\"\n",
    "plot_validation_curves(title,\"C\",param_range,train_scores,test_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-ne42oXPab1"
   },
   "outputs": [],
   "source": [
    "#get weights\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "coefs = get_coefs(X_train, X_test, y_train, y_test, \"pos\")\n",
    "coefs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bonM5h0z1NVI"
   },
   "source": [
    "# **Data Loading and Saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yB9N5IgukbqP"
   },
   "outputs": [],
   "source": [
    "#load data for CS106B and save them to google drive for future use\n",
    "X, y = getStudentFeatures(\"CS106B\")\n",
    "X.to_pickle(DATA_PATH+\"/CS106B_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS106B_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6s44B2-FtFu"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS110\")\n",
    "X.to_pickle(DATA_PATH+\"/CS110_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS110_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KeKja0uF10j"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS140\")\n",
    "X.to_pickle(DATA_PATH+\"/CS140_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS140_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6zMvOgCF8_v"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS155\")\n",
    "X.to_pickle(DATA_PATH+\"/CS155_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS155_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOy0V_FGGFKY"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS161\")\n",
    "X.to_pickle(DATA_PATH+\"/CS161_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS161_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPq74KV2GMJH"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS142\")\n",
    "X.to_pickle(DATA_PATH+\"/CS142_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS142_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYb5KCbZGVQ9"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS224S\")\n",
    "X.to_pickle(DATA_PATH+\"/CS224S_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS224S_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji54YciQGcGG"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS229\")\n",
    "X.to_pickle(DATA_PATH+\"/CS229_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS229_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Z_bHPXiGipc"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS129\")\n",
    "X.to_pickle(DATA_PATH+\"/CS129_X.pkl\")\n",
    "np.save(DATA_PATH+\"/CS129_y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vw2UtBe7wd0y"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "du6pMv489z24"
   },
   "source": [
    "\n",
    "# **Lasso Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGYnP7zf0Oix"
   },
   "outputs": [],
   "source": [
    "#This is a bad model. Leave here for reference\n",
    "def get_coefs_lasso(X_train, X_test, y_train, y_test):\n",
    "  model = Lasso(alpha=0.0001,precompute=True,max_iter=1000,positive=True, random_state=9999, selection='random')\n",
    "  model.fit(X_train, y_train)\n",
    "  coefs = [(X_train.columns[i], model.coef_[i]) for i in range(len(X_train.columns))]\n",
    "  coefs = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "  train_score = model.score(X_train,y_train)\n",
    "  test_score = model.score(X_test,y_test)\n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  print(\"test accuracy: %s\" % test_score)\n",
    "\n",
    "  return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1dihbOs5EjD"
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle(DATA_PATH+\"/CS142_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS142_y.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "coefs = get_coefs_lasso(X_train, X_test, y_train, y_test)\n",
    "coefs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EGNjHri969p"
   },
   "source": [
    "# **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJhUhBp45NGC"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def get_coefs_svm(X_train, X_test, y_train, y_test):\n",
    "  model = SVC(kernel='rbf',gamma='scale')\n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_train,y_train)\n",
    "  test_score = model.score(X_test,y_test)\n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  print(\"test accuracy: %s\" % test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3qLiBVg7ydG"
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle(DATA_PATH+\"/CS142_X.pkl\")\n",
    "y = np.load(DATA_PATH+\"/CS142_y.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "coefs = get_coefs_svm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rx7LlAD678Cq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dm8rtD-wT3W"
   },
   "source": [
    "# **Larger Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-zYKE4mwaEE"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS161\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMmYsyLSxIRu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "coefs = get_coefs(X_train, X_test, y_train, y_test, \"pos\")\n",
    "coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b5lCzkwxji-"
   },
   "outputs": [],
   "source": [
    "coefs = get_coefs(X, y, \"pos\")\n",
    "coefs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PraL7EMTynYU"
   },
   "outputs": [],
   "source": [
    "X.to_pickle(DATA_PATH+\"/CS161_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS229_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPNyQ36ozX6R"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS106B\")\n",
    "X.to_pickle(DATA_PATH+\"/CS106B_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS106B_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joyuW498zvHC"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS110\")\n",
    "X.to_pickle(DATA_PATH+\"/CS110_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS110_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vD94QIy01kHg"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS140\")\n",
    "X.to_pickle(DATA_PATH+\"/CS140_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS140_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly9teTMp1pvU"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS155\")\n",
    "X.to_pickle(DATA_PATH+\"/CS155_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS155_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUMayvFo1vs5"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS142\")\n",
    "X.to_pickle(DATA_PATH+\"/CS142_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS142_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlguyPI511j3"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS224S\")\n",
    "X.to_pickle(DATA_PATH+\"/CS224S_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS224S_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usIl3ZDN17XI"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS229\")\n",
    "X.to_pickle(DATA_PATH+\"/CS229_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS229_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNJgPMms2BHa"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS129\")\n",
    "X.to_pickle(DATA_PATH+\"/CS129_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS129_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZvJvajK2F6G"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures(\"CS161\")\n",
    "X.to_pickle(DATA_PATH+\"/CS161_X_plus.pkl\")\n",
    "np.save(DATA_PATH+\"/CS161_y_plus.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdA6121Z94a_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUA78T4VdCDm"
   },
   "source": [
    "# GLENN: Reducing number of coefficients (Lasso, PCA, and other attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SszbM7F8dKT1"
   },
   "outputs": [],
   "source": [
    "# need a different library to get p-values\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cs_ugrad_plus = pd.read_csv('/content/drive/My Drive/CS129 Carta project/data/cs_ug_plus.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZku3KrRdRBm"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures2(\"CS110\", cs_ugrad_plus)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jn8x3CZefIz"
   },
   "outputs": [],
   "source": [
    "# logit_model = sm.Logit(y, X)\n",
    "# result = logit_model.fit()\n",
    "# print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugt1tNoThn9-"
   },
   "source": [
    "Doesn't work (singular matrix). Let's try LASSO logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irbXCVa7hvPJ"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "model = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=1, max_iter=300) \n",
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train,y_train)\n",
    "test_score = model.score(X_test,y_test)\n",
    "coefs = [(X_train.columns[i], model.coef_[0][i]) for i in range(len(X_train.columns))]\n",
    "coefs_pos = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "coefs_neg = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "coefs_abs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "coefs_nonzero = sum([x[1] != 0 for x in coefs])\n",
    "coefs_zero = sum(x[1] == 0 for x in coefs)\n",
    "print(\"training accuracy: %s\" % train_score)\n",
    "print(\"test accuracy: %s\" % test_score)\n",
    "print(\"Number of nonzero/zero coefficients: %d/%d\" % (coefs_nonzero, coefs_zero))\n",
    "\n",
    "print(\"Largest absolute coefficients:\")\n",
    "pprint(coefs_abs[:10])\n",
    "print(\"Largest positive coefficients:\")\n",
    "pprint(coefs_pos[:10])\n",
    "print(\"Largest negative coefficients:\")\n",
    "pprint(coefs_neg[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtxA3z8Ilzrb"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=0.1, max_iter=300) \n",
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train,y_train)\n",
    "test_score = model.score(X_test,y_test)\n",
    "coefs = [(X_train.columns[i], model.coef_[0][i]) for i in range(len(X_train.columns))]\n",
    "coefs_pos = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "coefs_neg = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "coefs_abs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "coefs_nonzero = sum([x[1] != 0 for x in coefs])\n",
    "coefs_zero = sum(x[1] == 0 for x in coefs)\n",
    "print(\"training accuracy: %s\" % train_score)\n",
    "print(\"test accuracy: %s\" % test_score)\n",
    "print(\"Number of nonzero/zero coefficients: %d/%d\" % (coefs_nonzero, coefs_zero))\n",
    "\n",
    "print(\"Largest absolute coefficients:\")\n",
    "pprint(coefs_abs[:10])\n",
    "print(\"Largest positive coefficients:\")\n",
    "pprint(coefs_pos[:10])\n",
    "print(\"Largest negative coefficients:\")\n",
    "pprint(coefs_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvV2G-MVnOqz"
   },
   "outputs": [],
   "source": [
    "for i in [10, 3, 1, 0.3, 0.1, 0.03, 0.01]:\n",
    "  model = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=i, max_iter=300) \n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  coefs = [(X_train.columns[i], model.coef_[0][i]) for i in range(len(X_train.columns))]\n",
    "  coefs_pos = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "  coefs_neg = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "  coefs_abs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "  coefs_nonzero = sum([x[1] != 0 for x in coefs])\n",
    "  coefs_zero = sum(x[1] == 0 for x in coefs)\n",
    "  print(\"***** C = %f *****\" % i)\n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  print(\"test accuracy: %s\" % test_score)\n",
    "  print(\"Number of nonzero/zero coefficients: %d/%d\" % (coefs_nonzero, coefs_zero))\n",
    "  print(\"Largest absolute coefficients:\")\n",
    "  pprint(coefs_abs[:3])\n",
    "  print(\"Largest positive coefficients:\")\n",
    "  pprint(coefs_pos[:3])\n",
    "  print(\"Largest negative coefficients:\")\n",
    "  pprint(coefs_neg[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhGCtmcPorxY"
   },
   "outputs": [],
   "source": [
    "X, y = getStudentFeatures2(\"CS107\", cs_ugrad_plus)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "for i in [10, 3, 1, 0.3, 0.1, 0.03, 0.01]:\n",
    "  model = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=i, max_iter=300) \n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  coefs = [(X_train.columns[i], model.coef_[0][i]) for i in range(len(X_train.columns))]\n",
    "  coefs_pos = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "  coefs_neg = sorted(coefs, key = lambda x: x[1], reverse = False)\n",
    "  coefs_abs = sorted(coefs, key = lambda x: abs(x[1]), reverse = True)\n",
    "  coefs_nonzero = sum([x[1] != 0 for x in coefs])\n",
    "  coefs_zero = sum(x[1] == 0 for x in coefs)\n",
    "  print(\"***** C = %f *****\" % i)\n",
    "  print(\"training accuracy: %s\" % train_score)\n",
    "  print(\"test accuracy: %s\" % test_score)\n",
    "  print(\"Number of nonzero/zero coefficients: %d/%d\" % (coefs_nonzero, coefs_zero))\n",
    "  print(\"Largest absolute coefficients:\")\n",
    "  pprint(coefs_abs[:3])\n",
    "  print(\"Largest positive coefficients:\")\n",
    "  pprint(coefs_pos[:3])\n",
    "  print(\"Largest negative coefficients:\")\n",
    "  pprint(coefs_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skgOu6ApqRFY"
   },
   "outputs": [],
   "source": [
    "# accuracy seems weird, check ground truth\n",
    "\n",
    "print(sum([score == 1 for score in y_train]) / len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YhWit4Foqw2g"
   },
   "source": [
    "This model isn't doing much more than just predicting based on the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zz7fYdyEt0rm"
   },
   "source": [
    "# Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOGhTwzI3lVh"
   },
   "outputs": [],
   "source": [
    "cs_ugrad = pd.read_csv('/content/drive/My Drive/CS129 Carta project/data/cs_ug_plus.csv', header=0)\n",
    "top50courses = cs_ugrad.groupby('course_name').count().nlargest(50, 'strm').index.values\n",
    "topCourses = np.delete(top50courses,[8,14,18,29,30,38,39,40,45])\n",
    "topCourses = np.append(topCourses,'CS230')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQM0KbgVi-Gi"
   },
   "outputs": [],
   "source": [
    "#for topCourses\n",
    "results = []\n",
    "\n",
    "for course in topCourses:\n",
    "  X,y = getStudentFeatures(course)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  model = LogisticRegression(solver=\"lbfgs\")\n",
    "  model.fit(X_train, y_train)\n",
    "  #study coefficients\n",
    "  coefs = [(X.columns[i], model.coef_[0][i]) for i in range(len(X.columns))]\n",
    "  coefs = sorted(coefs, key = lambda x: x[1], reverse = True)\n",
    "  coefs_top20 = coefs[:20]\n",
    "  prereqInCoef = PrereqPredicted(course, coefs_top20)\n",
    "\n",
    "  #model evaluation\n",
    "  train_score = model.score(X_train, y_train)\n",
    "  y_pred_train = model.predict(X_train)\n",
    "  train_precision, train_recall, train_fscore, train_support = precision_recall_fscore_support(y_train, y_pred_train, average=\"binary\")\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  y_pred_test = model.predict(X_test)\n",
    "  test_precision, test_recall, test_fscore, test_support = precision_recall_fscore_support(y_test, y_pred_test, average=\"binary\")\n",
    "  \n",
    "  #save results\n",
    "  result = {\n",
    "    'course_name': course, \n",
    "    'train_accuracy': train_score, \n",
    "    'train_precision': train_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'train_fscore': train_fscore, \n",
    "    'test_accuracy': test_score, \n",
    "    'test_precision': test_precision, \n",
    "    'test_recall': test_recall, \n",
    "    'test_fscore': test_fscore,\n",
    "    'official_prereq_in_coefs': prereqInCoef,\n",
    "    'coefs': coefs_top20\n",
    "  }\n",
    "  print(result)\n",
    "  results.append(result)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_pickle(DATA_PATH+\"/topResults.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVSelKoBvS0N"
   },
   "outputs": [],
   "source": [
    "results.to_csv(DATA_PATH+\"/topResults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgyVtnrSc6l3"
   },
   "outputs": [],
   "source": [
    "results.to_pickle(DATA_PATH+\"/topResultsWith230.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTUQTkRF3Y30"
   },
   "outputs": [],
   "source": [
    "cs_ugrad = pd.read_csv('/content/drive/My Drive/CS129 Carta project/data/cs_ug_plus.csv', header=0)\n",
    "top50courses = cs_ugrad.groupby('course_name').count().nlargest(50, 'strm').index.values\n",
    "topCourses = np.delete(top50courses,[8,14,18,29,30,38,39,40,45])\n",
    "topCourses = np.append(topCourses,'CS230')\n",
    "\n",
    "#encode the data for scatter plot\n",
    "def encode_course(course):\n",
    "    encode = np.where(topCourses == course)\n",
    "    if not encode[0]:\n",
    "      encode = -1\n",
    "    else:\n",
    "      encode = encode[0][0]\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "guHhi4FD8POY"
   },
   "outputs": [],
   "source": [
    "#generate coordinates for one course\n",
    "def generate_coordinates(course, prereq):\n",
    "  x = [encode_course(course)] * len(prereq)\n",
    "  y = [encode_course(i) for i in prereq]\n",
    "  return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMSxByAfAfRZ"
   },
   "outputs": [],
   "source": [
    "#generate scatter plot\n",
    "\n",
    "results = pd.read_pickle(DATA_PATH+\"/topResultsWith230.pkl\")\n",
    "prereq_db = pickle.load(open(DATA_PATH+\"/prereq_db.pkl\", \"rb\"))\n",
    "f = plt.figure()\n",
    "\n",
    "for row_index, row in results.iterrows():\n",
    "  course = row['course_name']\n",
    "  #draw official prereqs\n",
    "  dp_code = re.findall(\"[A-Z]+\", course)[0]\n",
    "  official_prereq = [dp_code + str(i) for i in prereq_db[course]]\n",
    "  x_0, y_0 = generate_coordinates(course, official_prereq)\n",
    "  plt.scatter(x_0, y_0, c='r')\n",
    "\n",
    "  #draw prereq in coefs\n",
    "  prereq_in_coefs = row['official_prereq_in_coefs']\n",
    "  x_1, y_1 = generate_coordinates(course, prereq_in_coefs)\n",
    "  plt.scatter(x_1, y_1, c='y')\n",
    "\n",
    "  #draw coefs\n",
    "  coefs = row['coefs']\n",
    "  coefs_courses = [i[0] for i in coefs]\n",
    "  coefs_weights = [i[1] for i in coefs]\n",
    "  x_2, y_2 = generate_coordinates(course, coefs_courses)\n",
    "  plt.scatter(x_2, y_2, c='g', s=coefs_weights)\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.set_ylim(bottom=0.)\n",
    "ax.set_xlim(left=0.)\n",
    "plt.xlabel(\"top 40 Courses\")\n",
    "plt.ylabel(\"prereqs\")\n",
    "ax.set_xticks([24,41])\n",
    "ax.set_xticklabels(['CS229','CS230'])\n",
    "plt.yticks([])\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='official_prereq',\n",
    "                          markerfacecolor='r', markersize=15),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='predict_coefs',\n",
    "                          markerfacecolor='g', markersize=15),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='official_prereq_in_coefs',\n",
    "                          markerfacecolor='y', markersize=15)\n",
    "                   ]\n",
    "ax.legend(handles=legend_elements)\n",
    "plt.show()\n",
    "\n",
    "f.savefig(DATA_PATH+\"/result.pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "io0kcPR0ee-m"
   },
   "source": [
    "# ExploreCourses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9HdjelWem07"
   },
   "outputs": [],
   "source": [
    "! pip install explorecourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sli_ebyerTp"
   },
   "outputs": [],
   "source": [
    "from explorecourses import *\n",
    "from explorecourses import filters\n",
    "connect = CourseConnection()\n",
    "CScourses = connect.get_courses_by_department(\"CS\")\n",
    "EEcourses = connect.get_courses_by_department(\"EE\")\n",
    "STATScourses = connect.get_courses_by_department(\"STATS\")\n",
    "CMEcourses = connect.get_courses_by_department(\"CME\")\n",
    "MATHcourses = connect.get_courses_by_department(\"MATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bsh29jWt7JW"
   },
   "outputs": [],
   "source": [
    "#scraping numbers from course description and append the course code to it as a dictionary.\n",
    "# prerequisites_db = {\n",
    "#     'course code': []\n",
    "# }\n",
    "\n",
    "for course in courses:\n",
    "#  print(course.code)\n",
    "  prerequisites = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', course.description)]\n",
    "  prerequisites = [round(x) for x in prerequisites]\n",
    "#  print(prerequisites)\n",
    "  prerequisites_db['EE'+course.code] = prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOau3t2hvJk7"
   },
   "outputs": [],
   "source": [
    "#data saving\n",
    "f = open(DATA_PATH+\"/prereq_db.pkl\", \"wb\")\n",
    "pickle.dump(prerequisites_db, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baLYpn-B2Ijl"
   },
   "outputs": [],
   "source": [
    "# a helper function to check if coefs contains any official prereqs\n",
    "prereq_db = pickle.load(open(DATA_PATH+\"/prereq_db.pkl\", \"rb\"))\n",
    "def PrereqPredicted(course, coefs):\n",
    "  prereqInCoef = []\n",
    "  for i in coefs:\n",
    "    course_code = re.findall(\"\\d+\", i[0])[0]\n",
    "    for j in prereq_db[course]:\n",
    "      if j == int(course_code):\n",
    "        prereqInCoef.append(i[0])\n",
    "#    prereqInCoef = [i[0] for j in prereq_db[course] if int(course_code) == j]\n",
    "  return prereqInCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93aomSknhavB"
   },
   "outputs": [],
   "source": [
    "#manually check the official prereq dict\n",
    "prereq_db = pickle.load(open(DATA_PATH+\"/prereq_db.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaWPQoR3dbgx"
   },
   "outputs": [],
   "source": [
    "for course in topCourses:\n",
    "  print(course + \": \" + str(prereq_db[course]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sA7ga-fZeGwR"
   },
   "outputs": [],
   "source": [
    "prereq_db['CS105']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jZd26EpeQSF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0PCxvZEfJKq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Abdallah - Copy of final project.ipynb",
   "provenance": [
    {
     "file_id": "15M7mGpvkAqoxI_Zfr1eDwzSDriIi0Rag",
     "timestamp": 1574302635518
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
